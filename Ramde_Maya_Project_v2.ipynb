{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "KF8J-OLcd1cg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import os.path as op\n",
        "import json\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import logging\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from skimage import io\n",
        "import keras\n",
        "import math\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import random\n",
        "from PIL import Image\n",
        "from tensorflow.keras import layers, models, regularizers, callbacks\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, ReLU, MaxPooling2D, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "from tensorflow.keras.applications import efficientnet, vgg16\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, GlobalMaxPooling2D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "random_state = 42"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "W44XINje6W30",
        "outputId": "ad7f6925-ad73-410b-a6e6-cc20da9417b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.14.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.59.3)\n",
            "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n",
            "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount drive to Colab notebook\n",
        "from google.colab import drive\n",
        "#drive.flush_and_unmount()\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RF16z2MwgT85",
        "outputId": "a533f9c3-6d72-4d1a-f5be-33e215a70035"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Uploaded data.zip to my google drive. Now, unzip it and store in 552_project_data folder\n",
        "# zip_file_path = '/content/drive/MyDrive/Colab Notebooks/data.zip'\n",
        "# destination_folder = '/content/drive/MyDrive/552_project_data/'\n",
        "# !unzip \"$zip_file_path\" -d \"$destination_folder\""
      ],
      "metadata": {
        "id": "KQ6y6B2nh3ix"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "QGkoMFtod1ch"
      },
      "outputs": [],
      "source": [
        "# Logging configuration\n",
        "logging.basicConfig(level=logging.INFO,\n",
        "                    datefmt='%H:%M:%S',\n",
        "                    format='%(asctime)s | %(levelname)-5s | %(module)-15s | %(message)s')\n",
        "\n",
        "IMAGE_SIZE = (299, 299)  # All images contained in this dataset are 299x299 (originally, to match Inception v3 input size)\n",
        "SEED = 17\n",
        "\n",
        "# Head directory containing all image subframes. Update with the relative path of your data directory\n",
        "data_head_dir = Path('/content/drive/MyDrive/552_project_data/data')\n",
        "\n",
        "# Find all subframe directories\n",
        "subdirs = [Path(subdir.stem) for subdir in data_head_dir.iterdir() if subdir.is_dir()]\n",
        "src_image_ids = ['_'.join(a_path.name.split('_')[:3]) for a_path in subdirs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "XPU_EQM8d1ci"
      },
      "outputs": [],
      "source": [
        "# Load train/val/test subframe IDs\n",
        "def load_text_ids(file_path):\n",
        "    \"\"\"Simple helper to load all lines from a text file\"\"\"\n",
        "    with open(file_path, 'r') as f:\n",
        "        lines = [line.strip() for line in f.readlines()]\n",
        "    return lines\n",
        "\n",
        "# Load the subframe names for the three data subsets\n",
        "train_ids = load_text_ids('/content/drive/MyDrive/Colab Notebooks/train_source_images.txt')\n",
        "validate_ids = load_text_ids('/content/drive/MyDrive/Colab Notebooks/val_source_images.txt')\n",
        "test_ids = load_text_ids('/content/drive/MyDrive/Colab Notebooks/test_source_images.txt')\n",
        "\n",
        "# Generate a list containing the dataset split for the matching subdirectory names\n",
        "subdir_splits = []\n",
        "for src_id in src_image_ids:\n",
        "    if src_id in train_ids:\n",
        "        subdir_splits.append('train')\n",
        "    elif src_id in validate_ids:\n",
        "        subdir_splits.append('validate')\n",
        "    elif(src_id in test_ids):\n",
        "        subdir_splits.append('test')\n",
        "    else:\n",
        "        logging.warning(f'{src_id}: Did not find designated split in train/validate/test list.')\n",
        "        subdir_splits.append(None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uoXB_Xcd1ci"
      },
      "source": [
        "# Loading and pre processing the data\n",
        "### Note that there are multiple ways to preprocess and load your data in order to train your model in tensorflow. We have provided one way to do it in the following cell. Feel free to use your own method and get better results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "LwPB3JSQd1cj"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "\n",
        "def load_and_preprocess(img_loc, label):\n",
        "    def _inner_function(img_loc, label):\n",
        "        # Convert tensor to native type\n",
        "        img_loc_str = img_loc.numpy().decode('utf-8')\n",
        "\n",
        "        # Load image using PIL and convert to RGB\n",
        "        img = Image.open(img_loc_str).convert('RGB')\n",
        "\n",
        "        # Convert PIL image to numpy array\n",
        "        img = np.array(img)\n",
        "        img = tf.image.resize(img, [299, 299])\n",
        "\n",
        "        # Normalize the image to the [0, 1] range\n",
        "        img = img / 255.0\n",
        "\n",
        "        # Convert label to integer (assuming binary classification)\n",
        "        label = 1 if label.numpy().decode('utf-8') == 'frost' else 0\n",
        "        return img, label\n",
        "\n",
        "    # Wrap the Python function\n",
        "    X, y = tf.py_function(_inner_function, [img_loc, label], [tf.float32, tf.int64])\n",
        "\n",
        "    # Set the shape of the tensors\n",
        "    X.set_shape([299, 299, 3])\n",
        "    y.set_shape([]) # Scalar label\n",
        "\n",
        "    return X, y\n",
        "\n",
        "\n",
        "def load_subdir_data(dir_path, image_size, seed=None):\n",
        "\n",
        "    \"\"\"Helper to create a TF dataset from each image subdirectory\"\"\"\n",
        "\n",
        "    # Grab only the classes that (1) we want to keep and (2) exist in this directory\n",
        "    tile_dir = dir_path / Path('tiles')\n",
        "    label_dir = dir_path /Path('labels')\n",
        "\n",
        "    loc_list = []\n",
        "\n",
        "    for folder in os.listdir(tile_dir):\n",
        "        if os.path.isdir(os.path.join(tile_dir, folder)):\n",
        "            for file in os.listdir(os.path.join(tile_dir, folder)):\n",
        "                if file.endswith(\".png\"):\n",
        "                    loc_list.append((os.path.join(os.path.join(tile_dir, folder), file), folder))\n",
        "\n",
        "    return loc_list\n",
        "\n",
        "# Loop over all subframes, loading each into a list\n",
        "tf_data_train, tf_data_test, tf_data_val = [], [], []\n",
        "tf_dataset_train, tf_dataset_test, tf_dataset_val = [], [], []\n",
        "\n",
        "# Update the batch and buffer size as per your model requirements\n",
        "buffer_size = 64\n",
        "batch_size = 32\n",
        "\n",
        "for subdir, split in zip(subdirs, subdir_splits):\n",
        "    full_path = data_head_dir / subdir\n",
        "    if split=='validate':\n",
        "        tf_data_val.extend(load_subdir_data(full_path, IMAGE_SIZE, SEED))\n",
        "    elif split=='train':\n",
        "        tf_data_train.extend(load_subdir_data(full_path, IMAGE_SIZE, SEED))\n",
        "    elif split=='test':\n",
        "        tf_data_test.extend(load_subdir_data(full_path, IMAGE_SIZE, SEED))\n",
        "\n",
        "random.shuffle(tf_data_train)\n",
        "img_list, label_list = zip(*tf_data_train)\n",
        "img_list_t = tf.convert_to_tensor(img_list)\n",
        "lb_list_t = tf.convert_to_tensor(label_list)\n",
        "\n",
        "tf_dataset_train = tf.data.Dataset.from_tensor_slices((img_list_t, lb_list_t))\n",
        "tf_dataset_train = tf_dataset_train.map(load_and_preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "tf_dataset_train = tf_dataset_train.shuffle(buffer_size=buffer_size).batch(batch_size)\n",
        "\n",
        "random.shuffle(tf_data_val)\n",
        "img_list, label_list = zip(*tf_data_val)\n",
        "img_list_t = tf.convert_to_tensor(img_list)\n",
        "lb_list_t = tf.convert_to_tensor(label_list)\n",
        "\n",
        "tf_dataset_val = tf.data.Dataset.from_tensor_slices((img_list_t, lb_list_t))\n",
        "tf_dataset_val = tf_dataset_val.map(load_and_preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "tf_dataset_val = tf_dataset_val.shuffle(buffer_size=buffer_size).batch(batch_size)\n",
        "\n",
        "random.shuffle(tf_data_test)\n",
        "img_list, label_list = zip(*tf_data_test)\n",
        "img_list_t = tf.convert_to_tensor(img_list)\n",
        "lb_list_t = tf.convert_to_tensor(label_list)\n",
        "\n",
        "tf_dataset_test = tf.data.Dataset.from_tensor_slices((img_list_t, lb_list_t))\n",
        "tf_dataset_test = tf_dataset_test.map(load_and_preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "tf_dataset_test = tf_dataset_test.shuffle(buffer_size=buffer_size).batch(batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Dataset Length:\", len(tf_dataset_train))\n",
        "print(\"Validation Dataset Length:\", len(tf_dataset_val))\n",
        "print(\"Testing Dataset Length:\", len(tf_dataset_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pDi1UKqmP1Z",
        "outputId": "7202a8e4-d248-454b-c5de-e09dc66ccd64"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Dataset Length: 442\n",
            "Validation Dataset Length: 247\n",
            "Testing Dataset Length: 250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training CNN + MLP\n",
        "###### i. To perform empirical regularization, crop, randomly zoom, rotate, flip, con- trast, and translate images in your training set for image augmentation. You can use various tools to do this, including OpenCV."
      ],
      "metadata": {
        "id": "9i3IEw1itrlz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install tensorflow_addons\n",
        "import tensorflow_addons as tfa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7Ekkpaj0Z-N",
        "outputId": "1c22dea2-6626-4d72-e25e-f4458c686337"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.10/dist-packages (0.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (23.2)\n",
            "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (2.13.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example using data augmentation and smaller batch size\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Create an ImageDataGenerator for data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Fit the ImageDataGenerator on your training data\n",
        "datagen.flow(tf_dataset_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "hrz3172Xr0va",
        "outputId": "43e3d2c7-14b8-410f-832b-3e2fdca41487"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-32e163317375>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Fit the ImageDataGenerator on your training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_data_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/preprocessing/image.py\u001b[0m in \u001b[0;36mflow\u001b[0;34m(self, x, y, batch_size, shuffle, sample_weight, seed, save_to_dir, save_prefix, save_format, ignore_class_split, subset)\u001b[0m\n\u001b[1;32m   1543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1544\u001b[0m         \"\"\"\n\u001b[0;32m-> 1545\u001b[0;31m         return NumpyArrayIterator(\n\u001b[0m\u001b[1;32m   1546\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1547\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, image_data_generator, batch_size, shuffle, sample_weight, seed, data_format, save_to_dir, save_prefix, save_format, subset, ignore_class_split, dtype)\u001b[0m\n\u001b[1;32m    753\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplit_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    756\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_misc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_misc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '/content/drive/MyDrive/552_project_data/data/ESP_018951_1205_15360_20480_0_5120/tiles/frost/ESP_018951_1205_18060_18210_4350_4500.png'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ii) Train a three-layer CNN followed by a dense layer on the data. Choose the size of the kernels and depth of the layers and the number of neurons in the dense layer (MLP) on your own. Use ReLU’s in all of the layers. Use the softmax function, batch normalization3 and a dropout rate of 30%, L2 regularization, as well as ADAM optimizer. Use cross entropy loss. Train for at least 20 epochs and perform early stopping using the validation set. Keep the network parameters that have the lowest validation error. Plot the training and validation errors vs. epochs."
      ],
      "metadata": {
        "id": "hIODgaVQ039t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, ReLU, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "cnn_model = Sequential([\n",
        "    # block 1\n",
        "    Conv2D(32, (3, 3), padding = 'same', input_shape = (299, 299, 3), kernel_regularizer = l2(0.001)),\n",
        "    BatchNormalization(), ReLU(), MaxPooling2D(pool_size = (2, 2)),\n",
        "\n",
        "    # block 2\n",
        "    Conv2D(64, (3, 3), padding = 'same', kernel_regularizer = l2(0.001)),\n",
        "    BatchNormalization(), ReLU(), MaxPooling2D(pool_size = (2, 2)),\n",
        "\n",
        "    # block 3\n",
        "    Conv2D(128, (3, 3), padding = 'same', kernel_regularizer = l2(0.001)),\n",
        "    BatchNormalization(), ReLU(), MaxPooling2D(pool_size = (2, 2)),\n",
        "\n",
        "    # classifier\n",
        "    Flatten(),\n",
        "    Dense(128, activation = 'relu', kernel_regularizer = l2(0.001)),\n",
        "    Dropout(0.3), # 30% dropout rate\n",
        "    Dense(2, activation = 'softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "JYU1xoPeubs_"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model with ADAM optimizer and cross entropy loss\n",
        "cnn_model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Early stopping with validation set\n",
        "early_stop_criteria = EarlyStopping(monitor = 'val_loss', patience = 3, restore_best_weights = True)\n",
        "\n",
        "# Checkpoint to only keep network parameters with lowest validation error\n",
        "checkpoint = ModelCheckpoint('best_model.h5', monitor = 'val_loss', save_best_only = True)\n",
        "\n",
        "# Train model with training data set, 20 epochs, with callbacks on early stopping criteria and model's checkpoint\n",
        "cnn_history = cnn_model.fit(\n",
        "    datagen.fit(tf_dataset_train),\n",
        "    epochs = 20,\n",
        "    validation_data = tf_dataset_val,\n",
        "    callbacks = [early_stop_criteria, checkpoint],\n",
        "    verbose = 2  # Set verbosity level to 2 (One line per epoch logging)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "sY24qBRe1Ilw",
        "outputId": "cdf5a617-7421-46c0-ae66-325bb6f0f5ec"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-2d9f1ba03893>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Train model with training data set, 20 epochs, with callbacks on early stopping criteria and model's checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m cnn_history = cnn_model.fit(\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_dataset_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_dataset_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/preprocessing/image.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, augment, rounds, seed)\u001b[0m\n\u001b[1;32m   2084\u001b[0m             \u001b[0mseed\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mInt\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mRandom\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2085\u001b[0m         \"\"\"\n\u001b[0;32m-> 2086\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2087\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2088\u001b[0m             raise ValueError(\n",
            "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a real number, not '_BatchDataset'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Error rates\n",
        "cnn_train_error, cnn_validation_error = [], []\n",
        "for i in range(20):\n",
        "  train_err = 1 - model_cnn.history['accuracy'][i]\n",
        "  cnn_train_error.append(train_err)\n",
        "\n",
        "  val_err = 1 - model_cnn.history['val_accuracy'][i]\n",
        "  cnn_validation_error.append(val_err)\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Training & Validation Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(model_cnn.history['loss'], label = 'Training Loss', marker = 'o')\n",
        "plt.plot(model_cnn.history['val_loss'], label = 'Validation Loss', marker = 'o')\n",
        "plt.title('CNN Model: Training & Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Plot for Training and Validation Error\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(cnn_train_error, label = 'Training Error', marker = 'o')\n",
        "plt.plot(cnn_validation_error, label = 'Validation Error', marker = 'o')\n",
        "plt.title('CNN Model: Training & Validation Error')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Error Rate')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NequKbvyBRUr",
        "outputId": "9f43aa4f-bc4f-4d5c-fb42-d0022dc98c53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9ae4007dfdfe>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcnn_train_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn_validation_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mtrain_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmodel_cnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mcnn_train_error\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model_cnn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Report Precision, Recall, and F1 score for CNN model."
      ],
      "metadata": {
        "id": "KuElg_SsCzvu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# best model = least validation loss\n",
        "best_cnn_model = load_model('best_model.h5')\n",
        "# Predict on the test dataset\n",
        "cnn_predictions = best_cnn_model.predict(tf_dataset_test)\n",
        "\n",
        "predicted_labels = np.argmax(cnn_predictions, axis=1)\n",
        "\n",
        "# Extracting True Labels from the Test Dataset\n",
        "actual_labels = []\n",
        "for images, labels in tf_dataset_test.unbatch():\n",
        "    actual_labels.append(labels.numpy())\n",
        "\n",
        "true_labels = np.array(actual_labels)\n",
        "\n",
        "predicted_labels_flatten = predicted_labels.flatten()\n",
        "actual_labels_flatten = actual_labels.flatten()\n",
        "\n",
        "cnn_report = classification_report(actual_labels_flatten, predicted_labels_flatten)\n",
        "print(\"CNN Model Classification Report:\")\n",
        "print(cnn_report)"
      ],
      "metadata": {
        "id": "nEVGkKcmC6NW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## d) Transfer Learning"
      ],
      "metadata": {
        "id": "PMFPxk3L9FW5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### In this project, you will use pre-trained models (EfficientNetB0, ResNet50, and VGG16). For these pre-trained networks, you will only train the last fully connected layer, and will freeze all layers before them (i.e. we do not change their parameters during training) and use the outputs of the penultimate layer in the original pre-trained model as the features extracted from each image."
      ],
      "metadata": {
        "id": "SlkvY0rr9JCD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Must resize the images and recreate train/test/validation data sets\n",
        "def load_and_preprocess_v2(img_loc, label):\n",
        "    def _inner_function_v2(img_loc, label):\n",
        "      img_loc_str = img_loc.numpy().decode('utf-8')\n",
        "      img = Image.open(img_loc_str).convert('RGB')\n",
        "      img = img.resize((224, 224), Image.ANTIALIAS) # resize\n",
        "      img = np.array(img)\n",
        "      img = img / 255.0\n",
        "      label = 1 if label.numpy().decode('utf-8') == 'frost' else 0\n",
        "      return img, label\n",
        "\n",
        "    # Wrap the Python function\n",
        "    X, y = tf.py_function(_inner_function_v2, [img_loc, label], [tf.float32, tf.int64])\n",
        "\n",
        "    # Set the shape of the tensors\n",
        "    X.set_shape([224, 224, 3])  # new image size\n",
        "    y.set_shape([])  # Scalar label\n",
        "    return X, y\n",
        "\n",
        "\n",
        "IMAGE_SIZE = (224, 224)\n",
        "\n",
        "# Loop over all subframes, loading each into a list\n",
        "tf_data_train, tf_data_test, tf_data_val = [], [], []\n",
        "tf_dataset_train_raw, tf_dataset_test, tf_dataset_val = [], [], []\n",
        "\n",
        "# Update the batch and buffer size as per your model requirements\n",
        "buffer_size = 64\n",
        "batch_size = 5\n",
        "\n",
        "for subdir, split in zip(subdirs, subdir_splits):\n",
        "    full_path = data_head_dir / subdir\n",
        "    if split=='validate':\n",
        "        tf_data_val.extend(load_subdir_data(full_path, IMAGE_SIZE, SEED))\n",
        "    elif split=='train':\n",
        "        tf_data_train.extend(load_subdir_data(full_path, IMAGE_SIZE, SEED))\n",
        "    elif split=='test':\n",
        "        tf_data_test.extend(load_subdir_data(full_path, IMAGE_SIZE, SEED))\n",
        "\n",
        "random.shuffle(tf_data_train)\n",
        "img_list, label_list = zip(*tf_data_train)\n",
        "img_list_t = tf.convert_to_tensor(img_list)\n",
        "lb_list_t = tf.convert_to_tensor(label_list)\n",
        "\n",
        "tf_dataset_train_v2= tf.data.Dataset.from_tensor_slices((img_list_t, lb_list_t))\n",
        "tf_dataset_train_v2= tf_dataset_train_raw.map(load_and_preprocess_v2, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "tf_dataset_train_v2 = tf_dataset_train_raw.shuffle(buffer_size=buffer_size).batch(batch_size)\n",
        "\n",
        "random.shuffle(tf_data_val)\n",
        "img_list, label_list = zip(*tf_data_val)\n",
        "img_list_t = tf.convert_to_tensor(img_list)\n",
        "lb_list_t = tf.convert_to_tensor(label_list)\n",
        "\n",
        "tf_dataset_val_v2 = tf.data.Dataset.from_tensor_slices((img_list_t, lb_list_t))\n",
        "tf_dataset_val_v2 = tf_dataset_val.map(load_and_preprocess_v2, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "tf_dataset_val_v2 = tf_dataset_val.shuffle(buffer_size=buffer_size).batch(batch_size)\n",
        "\n",
        "random.shuffle(tf_data_test)\n",
        "img_list, label_list = zip(*tf_data_test)\n",
        "img_list_t = tf.convert_to_tensor(img_list)\n",
        "lb_list_t = tf.convert_to_tensor(label_list)\n",
        "\n",
        "tf_dataset_test_v2 = tf.data.Dataset.from_tensor_slices((img_list_t, lb_list_t))\n",
        "tf_dataset_test_v2 = tf_dataset_test.map(load_and_preprocess_v2, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "tf_dataset_test_v2 = tf_dataset_test.shuffle(buffer_size=buffer_size).batch(batch_size)"
      ],
      "metadata": {
        "id": "ac5a_M84Hd2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the augment function to each element in the dataset\n",
        "tf_dataset_train = tf_dataset_train_v2.map(augment_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
      ],
      "metadata": {
        "id": "RgNDF-NGZtXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VGG16"
      ],
      "metadata": {
        "id": "3EGerHLSI_co"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import VGG16, efficientnet\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "\n",
        "# Create VGG16 base model with pre-trained weights (include_top=False to exclude dense layers)\n",
        "vgg_base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "vgg_base.trainable = False  # Freeze\n",
        "\n",
        "model_vgg = Sequential([\n",
        "    vgg_base,\n",
        "    #Flatten(),\n",
        "    GlobalAveragePooling2D(),\n",
        "    BatchNormalization(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.3),  # 30% dropout rate\n",
        "    Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile model with ADAM optimizer and cross entropy loss\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Early stopping with patience = 3 and model checkpointing\n",
        "early_stop_criteria = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "checkpoint = ModelCheckpoint('best_model_vgg.h5', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "history_vgg = model_vgg.fit(\n",
        "    tf_dataset_train,\n",
        "    epochs = 10,\n",
        "    validation_data=tf_dataset_val,\n",
        "    callbacks=[early_stop_criteria, checkpoint]\n",
        ")"
      ],
      "metadata": {
        "id": "vmF6Wl8d9InV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Error rates\n",
        "vgg_train_error, vgg_validation_error = [], []\n",
        "\n",
        "for i in range(10):\n",
        "  train_err = 1 - history_vgg.history['accuracy'][i]\n",
        "  vgg_train_error.append(train_err)\n",
        "\n",
        "  val_err = 1 - history_vgg.history['val_accuracy'][i]\n",
        "  vgg_validation_error.append(val_err)\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Training & Validation Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history_vgg.history['loss'], label = 'Training Loss', marker = 'o')\n",
        "plt.plot(history_vgg.history['val_loss'], label = 'Validation Loss', marker = 'o')\n",
        "plt.title('VGG16 Model: Training & Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Plot for Training and Validation Error\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(cnn_train_error, label = 'Training Error', marker = 'o')\n",
        "plt.plot(cnn_validation_error, label = 'Validation Error', marker = 'o')\n",
        "plt.title('VGG16 Model: Training & Validation Error')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Error Rate')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ElG_2r9hKq3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Report Precision, Recall, and F1 score for VGG model."
      ],
      "metadata": {
        "id": "sK7HIlRrXnm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# best model = least validation loss\n",
        "best_vgg_model = load_model('best_model.h5')\n",
        "\n",
        "# pull actual Labels from test data\n",
        "actual_labels = []\n",
        "for images, labels in tf_dataset_test.unbatch():\n",
        "    actual_labels.append(labels.numpy())\n",
        "\n",
        "vgg_report = classification_report(np.array(actual_labels).flatten(), predicted_labels.flatten())\n",
        "print(\"VGG16 Model Classification Report:\")\n",
        "print(vgg_report)"
      ],
      "metadata": {
        "id": "f0LR4PzPXpda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ResNet50"
      ],
      "metadata": {
        "id": "z9015yG5WJkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet import preprocess_input\n",
        "\n",
        "base_resnet = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "base_resnet.trainable = False  # Freeze\n",
        "\n",
        "model_resnet = Sequential([\n",
        "    base_resnet,\n",
        "    GlobalAveragePooling2D(),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile model with ADAM optimizer and cross entropy loss\n",
        "model_resnet.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Early stopping with patience = 3 and model checkpointing\n",
        "early_stop_criteria = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "checkpoint = ModelCheckpoint('best_model_res.h5', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "history_resnet = model_resnet.fit(\n",
        "    tf_dataset_train,\n",
        "    epochs=10,\n",
        "    validation_data=tf_dataset_val,\n",
        "    callbacks=[early_stop_criteria, checkpoint]\n",
        ")"
      ],
      "metadata": {
        "id": "Qs-3TU5SWO6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Error rates\n",
        "resnet_train_error, resnet_validation_error = [], []\n",
        "\n",
        "for i in range(10):\n",
        "  train_err = 1 - history_resnet.history['accuracy'][i]\n",
        "  resnet_train_error.append(train_err)\n",
        "\n",
        "  val_err = 1 - history_resnet.history['val_accuracy'][i]\n",
        "  resnet_validation_error.append(val_err)\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Training & Validation Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history_resnet.history['loss'], label = 'Training Loss', marker = 'o')\n",
        "plt.plot(history_resnet.history['val_loss'], label = 'Validation Loss', marker = 'o')\n",
        "plt.title('ResNet50 Model: Training & Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Plot for Training and Validation Error\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(resnet_train_error, label = 'Training Error', marker = 'o')\n",
        "plt.plot(resnet_validation_error, label = 'Validation Error', marker = 'o')\n",
        "plt.title('ResNet50 Model: Training & Validation Error')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Error Rate')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XfyqTDHPXDfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Report Precision, Recall, and F1 score for ResNet50 model."
      ],
      "metadata": {
        "id": "wqUF4LNfYESD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# best model = least validation loss\n",
        "best_resnet_model = load_model('best_model.h5')\n",
        "\n",
        "# run model with test data\n",
        "resnet_predictions = best_resnet_model.predict(tf_dataset_test)\n",
        "\n",
        "predicted_labels = np.argmax(resnet_predictions, axis=1)\n",
        "\n",
        "# pull actual Labels from test data\n",
        "actual_labels = []\n",
        "for images, labels in tf_dataset_test.unbatch():\n",
        "    actual_labels.append(labels.numpy())\n",
        "\n",
        "resnet_report = classification_report(np.array(actual_labels).flatten(), predicted_labels.flatten())\n",
        "print(\"ResNet50 Model Classification Report:\")\n",
        "print(resnet_report)"
      ],
      "metadata": {
        "id": "h8K5jZSCYExP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EfficientNetB0"
      ],
      "metadata": {
        "id": "AZ1mg0AFZM5K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input"
      ],
      "metadata": {
        "id": "pyuzinqTZQrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_effnet = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "base_effnet.trainable = False  # Freeze\n",
        "\n",
        "model_reffnet = Sequential([\n",
        "    base_effnet,\n",
        "    GlobalAveragePooling2D(),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile model with ADAM optimizer and cross entropy loss\n",
        "model_reffnet.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Early stopping with patience = 3 and model checkpointing\n",
        "early_stop_criteria = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "checkpoint = ModelCheckpoint('best_model_res.h5', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "history_effnet = model_reffnet.fit(\n",
        "    tf_dataset_train,\n",
        "    epochs=10,\n",
        "    validation_data=tf_dataset_val,\n",
        "    callbacks=[early_stop_criteria, checkpoint]\n",
        ")"
      ],
      "metadata": {
        "id": "GJXMw636ZXFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Error rates\n",
        "effnet_train_error, effnet_validation_error = [], []\n",
        "\n",
        "for i in range(10):\n",
        "  train_err = 1 - history_effnet.history['accuracy'][i]\n",
        "  effnet_train_error.append(train_err)\n",
        "\n",
        "  val_err = 1 - history_effnet.history['val_accuracy'][i]\n",
        "  effnet_validation_error.append(val_err)\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Training & Validation Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history_effnet.history['loss'], label = 'Training Loss', marker = 'o')\n",
        "plt.plot(history_effnet.history['val_loss'], label = 'Validation Loss', marker = 'o')\n",
        "plt.title('EfficientNetB0 Model: Training & Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Plot for Training and Validation Error\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(effnet_train_error, label = 'Training Error', marker = 'o')\n",
        "plt.plot(effnet_validation_error, label = 'Validation Error', marker = 'o')\n",
        "plt.title('EfficientNetB0 Model: Training & Validation Error')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Error Rate')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ri1d3ecgZ8DF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Report Precision, Recall, and F1 score for EfficientNetB0 model."
      ],
      "metadata": {
        "id": "7YPsq-MUaKoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# best model = least validation loss\n",
        "best_effnet_model = load_model('best_model.h5')\n",
        "\n",
        "# run model with test data\n",
        "effnet_predictions = best_effnet_model.predict(tf_dataset_test)\n",
        "\n",
        "predicted_labels = np.argmax(effnet_predictions, axis=1)\n",
        "\n",
        "# pull actual Labels from test data\n",
        "actual_labels = []\n",
        "for images, labels in tf_dataset_test.unbatch():\n",
        "    actual_labels.append(labels.numpy())\n",
        "\n",
        "effnet_report = classification_report(np.array(actual_labels).flatten(), predicted_labels.flatten())\n",
        "print(\"EfficientNetB0 Model Classification Report:\")\n",
        "print(effnet_report)"
      ],
      "metadata": {
        "id": "vCszBZUsaK67"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}